{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лекция 2  BM5    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    " \n",
    "# инициализируем\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# составляем корпус документов\n",
    "corpus = [\n",
    "  'слово1 слово2 слово3',\n",
    "  'слово2 слово3',\n",
    "  'слово1 слово2 слово1',\n",
    "  'слово4'\n",
    "]\n",
    "\n",
    "# считаем\n",
    "X = vectorizer.fit_transform(corpus)\n",
    " \n",
    "# получится следующая структура:\n",
    "#        |  слово1  |  слово2  |  слово3  |  слово4\n",
    "# текст1 |   0.6    |    0.5   |   0.6    |    0\n",
    "# текст2 |   0      |    0.6   |   0.8    |    0\n",
    "# текст3 |   0.9    |    0.4   |   0      |    0\n",
    "# текст4 |   0      |    0     |   0      |    1\n",
    " \n",
    "# чтобы получить сгенерированный словарь, из приведенной структуры TfidfVectorizer\n",
    "# порядок совпадает с матрицей\n",
    "vectorizer.get_feature_names()  # ['слово1', 'слово2', 'слово3', 'слово4']\n",
    " \n",
    "# чтобы узнать индекс токена в словаре\n",
    "vectorizer.vocabulary_.get('слово3') # вернет 2\n",
    " \n",
    "# показать матрицу\n",
    "X.toarray()\n",
    " \n",
    "# теперь можно быстро подсчитать вектор для нового документа\n",
    "new_doc = vectorizer.transform(['слово1 слово4 слово4']).toarray()  # результат [[0.36673901, 0, 0, 0.93032387]]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Далее идет работа, которую я делал до того, как пришлось пропускать занятия из-за защиты курсовой. \n",
    "Я посмотрел ее и понял, что не понял задание, когда делал. Поэтому пришлось переделывать, но удалять ячейки я не стал, потому что опирался на них в новом коде. Код, который я буду имплементировать в проект дан после, отделен еще одной чертой.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция ранжирования bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 1__:    \n",
    "Реализуйте поиск с метрикой *TF-IDF* через умножение матрицы на вектор.\n",
    "Что должно быть в реализации:\n",
    "- **ГОТОВО** проиндексированная база, где каждый документ представлен в виде вектора TF-IDF\n",
    "- **ГОТОВО** функция перевода входяшего запроса в вектор по метрике TF-IDF\n",
    "- ранжирование докуменов по близости к запросу по убыванию\n",
    "\n",
    "В качестве корпуса возьмите корпус вопросов в РПН по Covid2019. Он состоит из:\n",
    "> файл **answers_base.xlsx** - база ответов, у каждого ответа есть его номер, тематика и примеры вопросов, которые могут быть заданы к этому ответу. Сейчас проиндексировать надо именно примеры вопросов в качестве документов базы. Понимаете почему?\n",
    "\n",
    "> файл **queries_base.xlsx** - вопросы юзеров, к каждому из которых проставлен номер верного ответа из базы. Разделите эти вопросы в пропорции 70/30 на обучающую (проиндексированную как база) и тестовую (как запросы) выборки. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Сделать матрицу для базы запросов\n",
    "1. прочесть файл\n",
    "2. получить файл в пандас\n",
    "3. разделить матрицу пандас в 70/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# обозначение датафрейма со всеми запросами\n",
    "df = pd.read_csv(\"queries_base.tsv\", sep=\"\\t\")\n",
    "df.columns=[\"text\", \"connection\", \"theme\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# деление основного датафрейма со всеми запросами\n",
    "# на тренировочный и тестовый датафреймы\n",
    "perc70 = int(int(df.shape[0])/10*7)\n",
    "df_train = df.iloc[:perc70]\n",
    "df_test = df.iloc[perc70:]\n",
    "df_test.shape, df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сделать функцию перевода \n",
    "1. сделать функцию перевода строки, чтобы переводить запрос\n",
    "2. сделать функцию перевода матрицы пандас"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# перевод тестового и тренировочного датафреймов в TF-IDF матрицы\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "v = TfidfVectorizer()\n",
    "df_train_tfidf = v.fit_transform(df_train['text'].values.astype('U'))\n",
    "df_test_tfidf = v.transform(df_test['text'].values.astype('U'))\n",
    "df_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обозначение векторайзера и перевод строки \n",
    "# маска пожалуйста \n",
    "query = [0]\n",
    "query[0] = str((input('ваш запрос: ')))\n",
    "print(query)\n",
    "query_tfidf = v.transform(query)\n",
    "print(query_tfidf)\n",
    "type(query_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = df_train_tfidf.dot(query_tfidf.T).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_sorted = np.sort(answer, axis=0)\n",
    "answer_sorted = answer_sorted[::-1]\n",
    "answer_sorted[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "answer_sorted[i][0]\n",
    "while answer_sorted[i][0] != 0:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answers = pd.DataFrame()\n",
    "i = 0\n",
    "while answer_sorted[i][0] != 0:\n",
    "    doc_num = np.where(answer == answer_sorted[i][0])[0][0]\n",
    "    df_answers = df_answers.append(df.loc[doc_num])\n",
    "    i += 1\n",
    "df_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 2__:    \n",
    "Аналогичная задаче1 с другой метрикой \n",
    "\n",
    "Реализуйте поиск с метрикой *BM25* через умножение матрицы на вектор. Что должно быть в реализации:\n",
    "\n",
    "- проиндексированная база, где каждый документ представлен в виде вектора BM25\n",
    "- функция перевода входяшего запроса в вектор по метрике BM25\n",
    "- ранжирование докуменов по близости к запросу по убыванию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### реализуйте эту функцию ранжирования \n",
    "from math import log\n",
    "\n",
    "k = 2.0\n",
    "b = 0.75\n",
    "\n",
    "def bottom(dl, avgdl):\n",
    "    return k * ((1-b) + b * (float(dl)/float(avgdl)) )\n",
    "\n",
    "def bm25(n, f, qf, r, N, dl, avdl) -> float:\n",
    "    bottom_coef = bottom(dl, avdl)\n",
    "    idf_component = log( ( (r + 0.5) / (0 - r + 0.5) ) / ( (n - r + 0.5) / (N - n - R + r + 0.5)) )\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "# Здесь заканчивается кусок кода для опоры, начинается новый код."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string # для .punctuatuion \n",
    "import math # bm25\n",
    "from collections import OrderedDict # для сортировки\n",
    "from collections import Counter # для матрицы бм25\n",
    "\n",
    "from razdel import tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Препроцессинг\n",
    "\n",
    "У меня очень мало времени на создание финального проекта, поэтому для удобного использования данных в будущем, я буду сразу пропускать их через базовый препроцессинг, который потом можно будет улучшить на базе третьего задания, но его пока не сделал. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()\n",
    "stop = set(stopwords.words('russian'))\n",
    "\n",
    "def prep(unprep):\n",
    "    unprep = str(unprep)\n",
    "    unprep = unprep.lower()\n",
    "    unprep = unprep.replace('\\n', ' ') #.punctuation не прочтет\n",
    "    unprep = unprep.translate(str.maketrans('', '', string.punctuation))# https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string\n",
    "    unprep_tokenized = list(tokenize(unprep))\n",
    "    lemmas = [morph.parse(i.text)[0].normal_form for i in unprep_tokenized]\n",
    "    words = [i for i in lemmas if i not in stop]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание датафреймов с данными и получение корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# теперь читать можно сразу из экселя\n",
    "answers_df = pd.read_excel(\"answers_base.xlsx\")\n",
    "questions_df = pd.read_excel(\"queries_base.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# названия столбцов неудобно вызывать в pandas, переименую\n",
    "# тематика не понадобится\n",
    "answers_df.rename(columns={'Номер связки': 'connection', 'Текст вопросов': 'text'}, inplace=True)\n",
    "questions_df.rename(columns={'Номер связки\\n': 'connection', 'Текст вопроса': 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egor/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# делим на тест и трейн красиво, не слайсом\n",
    "train_df, test_df = train_test_split(questions_df, test_size=0.3)\n",
    "# объединяем все тренировочные тексты вопросов\n",
    "qa_df = pd.concat([answers_df, train_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>connection</th>\n",
       "      <th>text</th>\n",
       "      <th>Текст ответа</th>\n",
       "      <th>Тематика</th>\n",
       "      <th>Тематика</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>У ребенка в школе продлили каникулы. Могу ли я...</td>\n",
       "      <td>Листок временной нетрудоспособности (больничны...</td>\n",
       "      <td>БОЛЬНИЧНЫЙ ЛИСТ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Где сделать вакцинацию от коронавируса?\\nСущес...</td>\n",
       "      <td>Коронавирусы - это целое семейство вирусов, ко...</td>\n",
       "      <td>ВАКЦИНАЦИЯ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>326.0</td>\n",
       "      <td>Сколько стоит сделать вакцину от гриппа?\\nМожн...</td>\n",
       "      <td>Бесплатно пройти вакцинацию можно в Вашей меди...</td>\n",
       "      <td>ВАКЦИНАЦИЯ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>327.0</td>\n",
       "      <td>Могу я отказаться от вакцинации?\\nВ каких случ...</td>\n",
       "      <td>Согласно приказу Министерства здравоохранения ...</td>\n",
       "      <td>ВАКЦИНАЦИЯ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>328.0</td>\n",
       "      <td>Безопасна ли вакцинация?\\nОпасна ли вакцинация...</td>\n",
       "      <td>В соответствии с пунктами 1 и 2 статьи 12 Феде...</td>\n",
       "      <td>ВАКЦИНАЦИЯ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Добрый день, устроился на работу в город усинс...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ОГРАНИЧЕНИЯ, ПРОПУСКНАЯ СИСТЕМА И ПЕРЕМЕЩЕНИЕ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>887</td>\n",
       "      <td>308.0</td>\n",
       "      <td>&gt;Добрый день, \\n&gt;вернулись из Турции ( туристи...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ЗАКРЫТИЕ ГРАНИЦ, ОТКРЫТИЕ ГРАНИЦ РОССИИ И АВИА...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Здравствуйте, подскажите пожалуйста, если я пр...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ОГРАНИЧЕНИЯ, ПРОПУСКНАЯ СИСТЕМА И ПЕРЕМЕЩЕНИЕ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Скажите, пожалуйста, когда можно считать каран...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>КАРАНТИН, ИЗОЛЯЦИЯ, САМОИЗОЛЯЦИЯ\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Вы мне иак и не ответили. Что не обходимио дел...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>КАРАНТИН, ИЗОЛЯЦИЯ, САМОИЗОЛЯЦИЯ\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1652 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      connection                                               text  \\\n",
       "0           57.0  У ребенка в школе продлили каникулы. Могу ли я...   \n",
       "1           78.0  Где сделать вакцинацию от коронавируса?\\nСущес...   \n",
       "2          326.0  Сколько стоит сделать вакцину от гриппа?\\nМожн...   \n",
       "3          327.0  Могу я отказаться от вакцинации?\\nВ каких случ...   \n",
       "4          328.0  Безопасна ли вакцинация?\\nОпасна ли вакцинация...   \n",
       "...          ...                                                ...   \n",
       "550         37.0  Добрый день, устроился на работу в город усинс...   \n",
       "887        308.0  >Добрый день, \\n>вернулись из Турции ( туристи...   \n",
       "430         37.0  Здравствуйте, подскажите пожалуйста, если я пр...   \n",
       "1632         1.0  Скажите, пожалуйста, когда можно считать каран...   \n",
       "1550         1.0  Вы мне иак и не ответили. Что не обходимио дел...   \n",
       "\n",
       "                                           Текст ответа         Тематика  \\\n",
       "0     Листок временной нетрудоспособности (больничны...  БОЛЬНИЧНЫЙ ЛИСТ   \n",
       "1     Коронавирусы - это целое семейство вирусов, ко...       ВАКЦИНАЦИЯ   \n",
       "2     Бесплатно пройти вакцинацию можно в Вашей меди...       ВАКЦИНАЦИЯ   \n",
       "3     Согласно приказу Министерства здравоохранения ...       ВАКЦИНАЦИЯ   \n",
       "4     В соответствии с пунктами 1 и 2 статьи 12 Феде...       ВАКЦИНАЦИЯ   \n",
       "...                                                 ...              ...   \n",
       "550                                                 NaN              NaN   \n",
       "887                                                 NaN              NaN   \n",
       "430                                                 NaN              NaN   \n",
       "1632                                                NaN              NaN   \n",
       "1550                                                NaN              NaN   \n",
       "\n",
       "                                              Тематика   \n",
       "0                                                   NaN  \n",
       "1                                                   NaN  \n",
       "2                                                   NaN  \n",
       "3                                                   NaN  \n",
       "4                                                   NaN  \n",
       "...                                                 ...  \n",
       "550   ОГРАНИЧЕНИЯ, ПРОПУСКНАЯ СИСТЕМА И ПЕРЕМЕЩЕНИЕ ...  \n",
       "887   ЗАКРЫТИЕ ГРАНИЦ, ОТКРЫТИЕ ГРАНИЦ РОССИИ И АВИА...  \n",
       "430   ОГРАНИЧЕНИЯ, ПРОПУСКНАЯ СИСТЕМА И ПЕРЕМЕЩЕНИЕ ...  \n",
       "1632                 КАРАНТИН, ИЗОЛЯЦИЯ, САМОИЗОЛЯЦИЯ\\n  \n",
       "1550                 КАРАНТИН, ИЗОЛЯЦИЯ, САМОИЗОЛЯЦИЯ\\n  \n",
       "\n",
       "[1652 rows x 5 columns]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df = qa_df.drop(columns = ['Unnamed: 3','Unnamed: 4'])\n",
    "qa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# составляю корпус документов, как в примере\n",
    "corpus = []\n",
    "for question in qa_df['text']:\n",
    "    corpus.append(prep(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1652, 7410)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# делаю матричку для трейна\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(corpus)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сразу напишу перевод текста в вектор для запроса \n",
    "def txt_to_tfidf(txt, vectorizer):\n",
    "    txt = prep(txt)\n",
    "    return vectorizer.transform([txt]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теперь сделаю тестовый запрос и отранжирую ответ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Если я вернулся из-за границы и должен сдать тест на коронавирус в течении трех дней, то в какой срок я должен загрузить результаты на сайт госуслуг?\\xa0\\n'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# запросом будет текст из тестовой выборки под индексом, допустим, 1\n",
    "txt = test_df.text.values[1]\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# преобразуем запрос в вектор\n",
    "test_query = txt_to_tfidf(txt, vectorizer)\n",
    "test_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1652"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# транспонируем вектор, чтобы его можно было корректно умножить\n",
    "# на полученную ранее матрицу трейна.\n",
    "# получатся значения близости.\n",
    "test_answer = X_train.dot(test_query.T)\n",
    "# убедимся, что все сделали верно\n",
    "len(test_answer.T[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим самые популярные тексты и к каким ответам они привязаны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# совместим ответы с их номерами связок = list[ tuple(V, CONN), … ]\n",
    "test_answer_conn = list(zip(test_answer.T[0], qa_df['connection'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.452095129379077, 308.0),\n",
       " (0.43830992732692803, 6.0),\n",
       " (0.37465503294320923, 308.0),\n",
       " (0.35575890128910914, 308.0),\n",
       " (0.34420283138094426, 308.0),\n",
       " (0.34078527812031256, 308.0),\n",
       " (0.34057574605392016, 308.0),\n",
       " (0.3343846283059541, 308.0),\n",
       " (0.3307979114856545, 308.0),\n",
       " (0.3299929697198379, 308.0)]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# отсортируем список кортежей по значению близости по возрастанию\n",
    "sorted_tac = sorted(test_answer_conn, key=lambda tup_k: tup_k[0], reverse=True)\n",
    "sorted_tac[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый популярный ответ - 308 связка, отлично!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что нужно для этой части:\n",
    "1. Обратно индексированный словарь\n",
    "2. Векторизатор запроса\n",
    "3. Векторизатор трейна \n",
    "4. Создание матрицы по полученным функциям\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Словарь обратной индексации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_inversed(x_train):\n",
    "    x_train = x_train.toarray()\n",
    "    # это будет словарь вида dict('feature_name':[sum,  ind_1,ind_2, … ind_n,feature_index])\n",
    "    output_dict = {}\n",
    "    # маплю, получаю список названий фичей\n",
    "    f_names = vectorizer.get_feature_names()\n",
    "    for f_index, f_name in enumerate(f_names):\n",
    "        # сумма единичек по горизонтали по фичам \n",
    "        output_dict[f_name] = [int(sum(x_train[:, f_index]))]\n",
    "        for index, d_index in enumerate(x_train[:, f_index].tolist()):\n",
    "            # проход по вертикали - по каждому документу. если встречается, то записываем\n",
    "            if d_index != 0:\n",
    "                output_dict[f_name].append(d_index)\n",
    "        # последний параметр в списке для ключа-фичи - индекс фичи\n",
    "        output_dict[f_name].append(f_index)\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторизатор запроса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_vectorizer_small(txt, output_dict):\n",
    "    # создаем массив-строку из нулей длиной равной количеству фич-слов\n",
    "    new_v = np.zeros((1, len(output_dict)))\n",
    "    txt = prep(txt)\n",
    "    for word in txt.split(' '):\n",
    "        if word in output_dict.keys():\n",
    "            # заполним нужные места в новом векторе\n",
    "            new_v[0, output_dict[word][-1]] = 1\n",
    "    return new_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторизатор тренировочных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обратного индекса есть общепринятая формула для ранжирования *Okapi best match 25* ([Okapi BM25](https://ru.wikipedia.org/wiki/Okapi_BM25)).    \n",
    "Пусть дан запрос $Q$, содержащий слова  $q_1, ... , q_n$, тогда функция BM25 даёт следующую оценку релевантности документа $D$ запросу $Q$:\n",
    "\n",
    "$$ score(D, Q) = \\sum_{i}^{n} \\text{IDF}(q_i)*\\frac{TF(q_i,D)*(k+1)}{TF(q_i,D)+k(1-b+b\\frac{l(d)}{avgdl})} $$ \n",
    "где   \n",
    ">$TF(q_i,D)$ - частота слова $q_i$ в документе $D$      \n",
    "$l(d)$ - длина документа (количество слов в нём)   \n",
    "*avgdl* — средняя длина документа в коллекции    \n",
    "$k$ и $b$ — свободные коэффициенты, обычно их выбирают как $k$=2.0 и $b$=0.75   \n",
    "$$$$\n",
    "$\\text{IDF}(q_i)$ - это модернизированная версия IDF: \n",
    "$$\\text{IDF}(q_i) = \\log\\frac{N-n(q_i)+0.5}{n(q_i)+0.5},$$\n",
    ">> где $N$ - общее количество документов в коллекции   \n",
    "$n(q_i)$ — количество документов, содержащих $q_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_vectorizer_large(tf_val, ld, corpus, nq):\n",
    "    k = 2.0\n",
    "    b = 0.75\n",
    "    lcorp = len(corpus)\n",
    "    avgdl = sum([len(i.split(\" \")) for i in corpus]) / lcorp\n",
    "    IDF = np.log((lcorp-nq+0.5) / (nq+0.5))\n",
    "    TF = (tf_val * (k+1)) / (tf_val + k * (1-b+b*(ld / avgdl)))\n",
    "    return TF * IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализация матрицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(corpus)\n",
    "output_dict = dict_inversed(X_train)\n",
    "bm25_matrix = np.zeros((len(corpus), len(output_dict)))\n",
    "\n",
    "for txt_index, txt in enumerate(corpus):\n",
    "    words = txt.split(' ')\n",
    "    # посчитаем параметры для BM25\n",
    "    tf_val = collections.Counter(words)\n",
    "    ld = len(words)\n",
    "    for word in words:\n",
    "        if word in output_dict.keys():\n",
    "            bm25_matrix[txt_index, output_dict[word][-1]] = bm25_vectorizer_large(tf_val[word], ld, corpus, len(output_dict[word]) - 1)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сделаем запрос по тестовой выборке, как для TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = test_df.text.values[1]\n",
    "test_query = bm25_vectorizer_small(txt, output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.89236492,  5.42282486,  0.        , ..., -0.42726096,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_answer = bm25_matrix.dot(test_query.T)\n",
    "test_answer.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# совместим ответы с их номерами связок = list[ tuple(V, CONN), … ]\n",
    "test_answer_conn = list(zip(test_answer.T[0], qa_df['connection'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(21.422809684123482, 308.0),\n",
       " (20.46379378745481, 6.0),\n",
       " (19.830440142190596, 308.0),\n",
       " (17.72524128773616, 308.0),\n",
       " (17.319884634754775, 308.0),\n",
       " (16.535023339587845, 308.0),\n",
       " (16.37148241245886, 308.0),\n",
       " (16.260036869785537, 308.0),\n",
       " (16.170457492321397, 308.0),\n",
       " (15.485265384978952, 308.0)]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# отсортируем список кортежей по значению близости по возрастанию\n",
    "sorted_tac = sorted(test_answer_conn, key=lambda tup_k: tup_k[0], reverse=True)\n",
    "sorted_tac[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый популярный ответ - 308 связка, отлично! Результат по метрикам одинаковый!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
