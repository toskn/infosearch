{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njIerNEYXqVd"
   },
   "source": [
    "## Лекция 3  NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSWLPdN7XqVg"
   },
   "source": [
    "### __Задача 1__:\n",
    "\n",
    "Реализуйте 2 функции препроцессинга:\n",
    "\n",
    "- Удалить именованные сущности с помощью natasha (https://github.com/natasha/yargy)\n",
    "- Удалить именованные сущности с помощью deepmipt (https://github.com/deepmipt/ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByaLfA77XqVh"
   },
   "source": [
    "# Наташа "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eG2fSWlOYmFV"
   },
   "outputs": [],
   "source": [
    "!pip install deeppavlov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nnClz26Salsx"
   },
   "outputs": [],
   "source": [
    "!pip install natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDpaOvaOdvsu"
   },
   "outputs": [],
   "source": [
    "!python -m deeppavlov install ner_ontonotes_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "UV-nLKXTXqVi",
    "outputId": "8e3343b6-90ad-416c-ede1-abb5872a8b75"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-22 08:46:27.208 INFO in 'deeppavlov.download'['download'] at line 132: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_v1.tar.gz download because of matching hashes\n",
      "2020-10-22 08:46:30.922 INFO in 'deeppavlov.download'['download'] at line 132: Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_rus_bert_v1.tar.gz download because of matching hashes\n",
      "2020-10-22 08:46:31.314 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_rus_bert/tag.dict]\n",
      "2020-10-22 08:47:02.567 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_rus_bert/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_rus_bert/model\n"
     ]
    }
   ],
   "source": [
    "#natasha part\n",
    "from natasha import (\n",
    "    Segmenter,\n",
    "    NewsNERTagger,\n",
    "    NewsEmbedding,\n",
    "    Doc\n",
    ")\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "segmenter = Segmenter()\n",
    "\n",
    "#deepmit part\n",
    "from deeppavlov import configs, build_model\n",
    "ner_model = build_model(configs.ner.ner_rus_bert, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7oyrNM5eXqVm"
   },
   "outputs": [],
   "source": [
    "text = 'Посол Израиля на Украине Йоэль Лион признался, что пришел в шок, узнав о решении властей Львовской области объявить 2019 год годом лидера запрещенной в России Организации украинских националистов (ОУН) Степана Бандеры...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "G2YTSBv6XqVq"
   },
   "outputs": [],
   "source": [
    "# need to remove PERSON, LOCATION, ORGANISATION, TIME\n",
    "def preprocess_with_natasha(text: str) -> str:\n",
    "    text = str(text)\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_ner(ner_tagger)\n",
    "    positions = []\n",
    "    for element in doc.spans:\n",
    "        positions.append([element.start, element.stop])\n",
    "    lst = list(text)\n",
    "    for i in positions[::-1]: # iterate from behind so index does not shrink inwards\n",
    "        del lst[slice(*i)]\n",
    "    text = ''.join(lst)\n",
    "    text = text.replace('  ', ' ')\n",
    "    text = text.replace('  ', ' ')\n",
    "    text = text.replace(' .', '.')\n",
    "    print(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "nQg0itvKXqVu",
    "outputId": "1340b375-3058-4dea-8f92-b4f79408c407"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Посол на признался, что пришел в шок, узнав о решении властей объявить 2019 год годом лидера запрещенной в...\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Посол на признался, что пришел в шок, узнав о решении властей объявить 2019 год годом лидера запрещенной в...'"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_with_natasha(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZuNY3v9XqVy"
   },
   "source": [
    "# deepmipt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "45DhEeRWXqVy"
   },
   "outputs": [],
   "source": [
    "def preprocess_with_deepmipt(text: str) -> str:\n",
    "  text = str(text)\n",
    "  text = ner_model([text])\n",
    "  # слова\n",
    "  sentence = text[0][0]\n",
    "  # теги к словам\n",
    "  tags = text[1][0]\n",
    "  # совмещаем в один объект\n",
    "  tags_and_words = list(zip(sentence, tags))\n",
    "  # сюда запишу где именованные сущности\n",
    "  counter = []\n",
    "  for entity in tags_and_words:\n",
    "    if entity[1] != 'O':\n",
    "      counter.append(tags_and_words.index(entity))\n",
    "  no_named = [ elem for elem in tags_and_words if tags_and_words.index(elem) not in counter]\n",
    "  # сюда запишу список нужных слов для возвращения к тексту от списка слов\n",
    "  words = []\n",
    "  for pair in no_named:\n",
    "    words.append(pair[0])\n",
    "  return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "NUIgfmTkgJTK",
    "outputId": "9d5dbc91-be8a-482b-f2d9-0ce9c6edb515"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Посол на признался , что пришел в шок , узнав о решении властей объявить 2019 год годом лидера запрещенной в . . .'"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_with_deepmipt(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXd2A65sXqV2"
   },
   "source": [
    "### Добавления к препроцессингу\n",
    "Кроме того, для соответствия препроцессингу в предыдущем задании и в надежде улучшить результат я добавлю несколько операций над текстом в препроцессинге.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "Sw92qSpWeE3Z"
   },
   "outputs": [],
   "source": [
    "# для работы моего препроцессинга и запуска в дальнейшем с тф-идф и бм25\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string # для .punctuatuion \n",
    "import math # bm25\n",
    "from collections import OrderedDict # для сортировки\n",
    "from collections import Counter # для матрицы бм25\n",
    "\n",
    "from razdel import tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "eIJxH9SNXqV2"
   },
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()\n",
    "stop = set(stopwords.words('russian'))\n",
    "\n",
    "def prep(unprep):\n",
    "    unprep = str(unprep)\n",
    "    unprep = unprep.lower()\n",
    "    unprep = unprep.replace('\\n', ' ') #.punctuation не прочтет\n",
    "    unprep = unprep.translate(str.maketrans('', '', string.punctuation))# https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string\n",
    "    unprep_tokenized = list(tokenize(unprep))\n",
    "    lemmas = [morph.parse(i.text)[0].normal_form for i in unprep_tokenized]\n",
    "    words = [i for i in lemmas if i not in stop]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C52AluzWXqV6"
   },
   "source": [
    "### __Задача 2__:    \n",
    "На предыдущем занятии вы реализовывали функции поиска ближайших ответов на запросы через TF-IDF и BM25. \n",
    "Сравните качество нахождения верного ответа для обоих методов в трех случаях:\n",
    "- с функцией ```preprocess_with_natasha```\n",
    "- с функцией ```preprocess_with_deepmipt```\n",
    "- без препроцессинга\n",
    "\n",
    "Для измерения качества используйте метрику accuracy. Считаем, что ответ верный, если он входит в топ-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neVBWHE8sAPV"
   },
   "source": [
    "## Что теперь делать?\n",
    "Препроцессинг получился: работает наташа, диппавлов и мой небольшой препроцессинг из прошлой работы. Остается только скопировать предыдущую тетрадку и добавить к строчкам применения моей функции препроцессинга полученные новые: наташу и диппавлова.\n",
    "\n",
    "Добавлять строчки придется с небольшими изменениями, потому что нужно посчитать точность. Кроме того, однокурсники посоветовали мне пользоваться tqdm, чтобы следить за реализацией препроцессинга, который может затягиваться.\n",
    "\n",
    "Таким образом мне необходимо:\n",
    "1. вставить базовый код прошлого задания\n",
    "2. разобраться с tqdm \n",
    "3. запустить препроцессинг на тест и на трейн с tqdm\n",
    "4. получить тест и трейн матрицы\n",
    "5. посчитать точность выбора по связкам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "2HyZYTV1r_Sc"
   },
   "outputs": [],
   "source": [
    "# теперь читать можно сразу из экселя\n",
    "answers_df = pd.read_excel(\"answers_base.xlsx\")\n",
    "questions_df = pd.read_excel(\"queries_base.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "6OjdOaYFtyNn"
   },
   "outputs": [],
   "source": [
    "# названия столбцов неудобно вызывать в pandas, переименую\n",
    "# тематика не понадобится\n",
    "answers_df.rename(columns={'Номер связки': 'connection', 'Текст вопросов': 'text'}, inplace=True)\n",
    "questions_df.rename(columns={'Номер связки\\n': 'connection', 'Текст вопроса': 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eLWbGArquDQx"
   },
   "outputs": [],
   "source": [
    "# делим на тест и трейн красиво, не слайсом\n",
    "train_df, test_df = train_test_split(questions_df, test_size=0.3)\n",
    "# объединяем все тренировочные тексты вопросов\n",
    "qa_df = pd.concat([answers_df, train_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2QbWeEGuEa9"
   },
   "outputs": [],
   "source": [
    "qa_df = qa_df.drop(columns = ['Unnamed: 3','Unnamed: 4'])\n",
    "qa_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juJVBL_RvAS6"
   },
   "source": [
    "## НАТАША + TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ts0bJZ2uMWXq"
   },
   "outputs": [],
   "source": [
    "# попробую сделать заполняемые строки tqdm\n",
    "# ПРЕПРОЦЕССИНГ\n",
    "from tqdm import tqdm\n",
    "test_df_done = []\n",
    "qa_df_done = []\n",
    "\n",
    "for entry in tqdm(test_df['text']):\n",
    "    test_df_done.append(prep(preprocess_with_natasha(entry)))\n",
    "for entry in tqdm(qa_df['text']):\n",
    "    qa_df_done.append(prep(preprocess_with_natasha(entry)))\n",
    "\n",
    "both_done = qa_df_done + test_df_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "TKInIAdju8Sn",
    "outputId": "0853283f-376d-4d9c-9d25-f598c3807131"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1652, 7588)\n",
      "(690, 7588)\n"
     ]
    }
   ],
   "source": [
    "# сделаем фит и матрицы по нему для теста и трейна\n",
    "vectorizer = TfidfVectorizer(both_done)\n",
    "fit_vec = vectorizer.fit_transform(both_done)\n",
    "X_train = vectorizer.transform(qa_df_done)\n",
    "print(X_train.shape)\n",
    "X_test = vectorizer.transform(test_df_done)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "XCwDOVHOuG4a"
   },
   "outputs": [],
   "source": [
    "# осталось только посчитать точность работы алгоритма\n",
    "\n",
    "rating = X_train.dot(X_test.T).argmax(axis=0)\n",
    "# в следующей ячейке у меня не получилось сделать проверку на nan через pandas,\n",
    "# поэтому будет массив нампай\n",
    "rating = np.array(rating)[0]\n",
    "rating_en = enumerate(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "MlvlhMd2v8SW"
   },
   "outputs": [],
   "source": [
    "score = 0\n",
    "# сравним связки\n",
    "for test_index, prediction in rating_en:\n",
    "    # проверка на NaN\n",
    "    if math.isnan(test_df.iloc[test_index].connection) or math.isnan(qa_df.iloc[prediction].connection):\n",
    "        continue\n",
    "\n",
    "    # если в тесте и трейне совпала связка по посчитанным индексам из рейтинга, модели плюс очко\n",
    "    if int(test_df.iloc[test_index].connection) == int(qa_df.iloc[prediction].connection):\n",
    "        score += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "Wb3_K3UWTTQT",
    "outputId": "73b4107d-710e-4b38-a15b-56c6a6e91a4e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'natasha + TF-IDF: 0.5246376811594203'"
      ]
     },
     "execution_count": 96,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"natasha + TF-IDF: \" + str(score / len(rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svJ0znaMXu_m"
   },
   "source": [
    "# DEEP PAVLOV + TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vgL5NwdYkUv"
   },
   "source": [
    "на этом этапе оказалось, что нужно резать вхождения в диппавлов до 300 символов, которые примерно равны 512 токенам БЕРТа. Иначе ничего не будет работать. https://github.com/deepmipt/DeepPavlov/issues/839"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9bSxQa5eyk-"
   },
   "source": [
    "Поэтому была переписана функция процессинга с диппавловым"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "sshLqHjQaA-0"
   },
   "outputs": [],
   "source": [
    "def deepmipt_helper(text):\n",
    "    text = ner_model([text])\n",
    "  # слова\n",
    "    sentence = text[0][0]\n",
    "  # теги к словам\n",
    "    tags = text[1][0]\n",
    "  # совмещаем в один объект\n",
    "    tags_and_words = list(zip(sentence, tags))\n",
    "  # сюда запишу где именованные сущности\n",
    "  counter = []\n",
    "    for entity in tags_and_words:\n",
    "        if entity[1] != 'O':\n",
    "            counter.append(tags_and_words.index(entity))\n",
    "    no_named = [ elem for elem in tags_and_words if tags_and_words.index(elem) not in counter]\n",
    "  # сюда запишу список нужных слов для возвращения к тексту от списка слов\n",
    "    words = []\n",
    "    for pair in no_named:\n",
    "        words.append(pair[0])\n",
    "    return ' '.join(words)\n",
    "\n",
    "def preprocess_with_deepmipt(text: str) -> str:\n",
    "    list_text = []\n",
    "    text = str(text)\n",
    "  # к сожалению, боюсь не успеть написать красиво через sentensize. прошу, простите\n",
    "    if len(text) > 300:\n",
    "        list_text = [text[i: i + 300] for i in range(0, len(text), 300)]\n",
    "        for part in list_text:\n",
    "            part = deepmipt_helper(part)\n",
    "        text = ' '.join(list_text)\n",
    "    else:\n",
    "        text = deepmipt_helper(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "U_nSIU87Xl4d",
    "outputId": "1ca92d80-24fd-4f38-b99b-4cc6fb760dc9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 690/690 [06:47<00:00,  1.69it/s]\n",
      "100%|██████████| 1652/1652 [16:09<00:00,  1.70it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df_done = []\n",
    "qa_df_done = []\n",
    "\n",
    "for entry in tqdm(test_df['text']):\n",
    "    test_df_done.append(prep(preprocess_with_deepmipt(entry)))\n",
    "for entry in tqdm(qa_df['text']):\n",
    "    qa_df_done.append(prep(preprocess_with_deepmipt(entry)))\n",
    "\n",
    "both_done = qa_df_done + test_df_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "D039rHgxlAlG",
    "outputId": "b13a31c3-213f-453d-cdee-cab106d097d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1652, 9775)\n",
      "(690, 9775)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(both_done)\n",
    "fit_vec = vectorizer.fit_transform(both_done)\n",
    "X_train = vectorizer.transform(qa_df_done)\n",
    "print(X_train.shape)\n",
    "X_test = vectorizer.transform(test_df_done)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "wdYhtEQ9lE5X"
   },
   "outputs": [],
   "source": [
    "# осталось только посчитать точность работы алгоритма\n",
    "\n",
    "rating = X_train.dot(X_test.T).argmax(axis=0)\n",
    "# в следующей ячейке у меня не получилось сделать проверку на nan через pandas,\n",
    "# поэтому будет массив нампай\n",
    "rating = np.array(rating)[0]\n",
    "rating_en = enumerate(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "irYXOxbClI4b"
   },
   "outputs": [],
   "source": [
    "score = 0\n",
    "# сравним связки\n",
    "for test_index, prediction in rating_en:\n",
    "    # проверка на NaN\n",
    "    if math.isnan(test_df.iloc[test_index].connection) or math.isnan(qa_df.iloc[prediction].connection):\n",
    "        continue\n",
    "\n",
    "    # если в тесте и трейне совпала связка по посчитанным индексам из рейтинга, модели плюс очко\n",
    "    if int(test_df.iloc[test_index].connection) == int(qa_df.iloc[prediction].connection):\n",
    "        score += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "0lPckDNOlOPP",
    "outputId": "06ee40c8-2107-44c6-a340-2bd0df427c6f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'диппавлов + TF-IDF: 0.5347826086956522'"
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"диппавлов + TF-IDF: \" + str(score / len(rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcsZSRNIfEZW"
   },
   "source": [
    "# БЕЗ ПРЕПРОЦЕССИНГА + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "-gb9QNB-YF8P",
    "outputId": "94c5937e-4923-4fa6-f667-5407b9dc8214"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 690/690 [00:00<00:00, 335738.95it/s]\n",
      "100%|██████████| 1652/1652 [00:00<00:00, 399365.43it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df_done = []\n",
    "qa_df_done = []\n",
    "\n",
    "for entry in tqdm(test_df['text']):\n",
    "    test_df_done.append(str(entry))\n",
    "for entry in tqdm(qa_df['text']):\n",
    "    qa_df_done.append(str(entry))\n",
    "\n",
    "both_done = qa_df_done + test_df_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "cVE9b47UfVTK",
    "outputId": "4cdd424e-fdcb-4b0e-9b92-2c9fcb768226"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1652, 14972)\n",
      "(690, 14972)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(both_done)\n",
    "fit_vec = vectorizer.fit_transform(both_done)\n",
    "X_train = vectorizer.transform(qa_df_done)\n",
    "print(X_train.shape)\n",
    "X_test = vectorizer.transform(test_df_done)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "PI3x9upEff6-"
   },
   "outputs": [],
   "source": [
    "# осталось только посчитать точность работы алгоритма\n",
    "\n",
    "rating = X_train.dot(X_test.T).argmax(axis=0)\n",
    "# в следующей ячейке у меня не получилось сделать проверку на nan через pandas,\n",
    "# поэтому будет массив нампай\n",
    "rating = np.array(rating)[0]\n",
    "rating_en = enumerate(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "Alq37sJifkJy"
   },
   "outputs": [],
   "source": [
    "score = 0\n",
    "# сравним связки\n",
    "for test_index, prediction in rating_en:\n",
    "    # проверка на NaN\n",
    "    if math.isnan(test_df.iloc[test_index].connection) or math.isnan(qa_df.iloc[prediction].connection):\n",
    "        continue\n",
    "\n",
    "    # если в тесте и трейне совпала связка по посчитанным индексам из рейтинга, модели плюс очко\n",
    "    if int(test_df.iloc[test_index].connection) == int(qa_df.iloc[prediction].connection):\n",
    "        score += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "-1POwbWVmBqm",
    "outputId": "0ac9ded5-8f5f-4305-87c8-f66c06ecbc76"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'без проц + TF-IDF: 0.5478260869565217'"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"без проц + TF-IDF: \" + str(score / len(rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-c_sKztCgOgG"
   },
   "source": [
    "# bm25 из прошлой работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dccAggQ-gjuz"
   },
   "source": [
    "### словарь обратн. инд."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xsRbvEhxgeVY"
   },
   "outputs": [],
   "source": [
    "def dict_inversed(x_train):\n",
    "    x_train = x_train.toarray()\n",
    "    # это будет словарь вида dict('feature_name':[sum,  ind_1,ind_2, … ind_n,feature_index])\n",
    "    output_dict = {}\n",
    "    # маплю, получаю список названий фичей\n",
    "    f_names = vectorizer.get_feature_names()\n",
    "    for f_index, f_name in enumerate(f_names):\n",
    "        # сумма единичек по горизонтали по фичам \n",
    "        output_dict[f_name] = [int(sum(x_train[:, f_index]))]\n",
    "        for index, d_index in enumerate(x_train[:, f_index].tolist()):\n",
    "            # проход по вертикали - по каждому документу. если встречается, то записываем\n",
    "            if d_index != 0:\n",
    "                output_dict[f_name].append(d_index)\n",
    "        # последний параметр в списке для ключа-фичи - индекс фичи\n",
    "        output_dict[f_name].append(f_index)\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ep4HHIRqgS5-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89hNy_pOf-Zv"
   },
   "source": [
    "# NATASHA + BM25 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSExQb6PjkG2"
   },
   "source": [
    "# простите, не успеваю, не буду запускать, тогда совсем не успею собрать никакой проект"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpxxz0iQXqV7"
   },
   "source": [
    "### __Задача 3__:    \n",
    "Улучшить правила в natasha. Написать правила, которые ловят даты в следующих примерах и пересчитать статистику из Задачи 2:\n",
    "- Уехал 8-9 ноября в Сочи\n",
    "- Уезжаю 5 числа                           \n",
    "- 20го сентября заболел\n",
    "\n",
    "Пример можно посмотреть тут: https://github.com/natasha/yargy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "oauS1k86XqV7",
    "outputId": "a2028823-d74a-4eff-bb9f-be7a9ae0228b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 17) ['8', '-', '9', 'ноября']\n",
      "[32, 39) ['5', 'числа']\n",
      "[40, 53) ['20', 'го', 'сентября']\n"
     ]
    }
   ],
   "source": [
    "# спасибо за помощь в реализации правил статье про разработку правил в ярги от Лаборатории Александра Кукушкина.\n",
    "from yargy import rule, and_, or_, Parser\n",
    "from yargy.predicates import gte, lte, caseless, normalized, dictionary\n",
    "\n",
    "DAY = and_(\n",
    "    gte(1),\n",
    "    lte(31)\n",
    ")\n",
    "MONTH = and_(\n",
    "    gte(1),\n",
    "    lte(12)\n",
    ")\n",
    "\n",
    "MONTHS = {\n",
    "    'январь',\n",
    "    'февраль',\n",
    "    'март',\n",
    "    'апрель',\n",
    "    'мая',\n",
    "    'июнь',\n",
    "    'июль',\n",
    "    'август',\n",
    "    'сентябрь',\n",
    "    'октябрь',\n",
    "    'ноябрь',\n",
    "    'декабрь'\n",
    "}\n",
    "\n",
    "MONTH_NAME = dictionary(MONTHS)\n",
    "DATE_WORDS = or_(\n",
    "    rule(normalized('число')),\n",
    "    rule(caseless('числа')),\n",
    "    rule(caseless('го'))\n",
    ")\n",
    "DATE = or_(\n",
    "    rule(\n",
    "        DAY,\n",
    "        DATE_WORDS.optional(),\n",
    "        MONTH_NAME\n",
    "    ),\n",
    "    rule(\n",
    "        DAY,\n",
    "        DATE_WORDS.optional(),\n",
    "        MONTH_NAME.optional()\n",
    "    ),\n",
    "    #Уехал 8-9 ноября в Сочи\n",
    "    rule(\n",
    "        DAY,\n",
    "        \"-\",\n",
    "        DAY,\n",
    "        MONTH_NAME,\n",
    "    )\n",
    ")\n",
    "parser = Parser(DATE)\n",
    "text = '''\n",
    "Уехал 8-9 ноября в Сочи\n",
    "Уезжаю 5 числа\n",
    "20го сентября заболел'''\n",
    "for match in parser.findall(text):\n",
    "    print(match.span, [_.value for _ in match.tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrQlGebCpZEQ"
   },
   "source": [
    "Правила улучшены, простите, что не пересчитываю статистику, мне нужно успеть доделать 4 задание, чтобы собрать проект."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2fpdDC3pj8P"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sem3_ner.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
