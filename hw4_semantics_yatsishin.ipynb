{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать реализацию Word2vec в библиотеке **Gensim**, а в качестве предобученных моделей возьмем модели Андрея Кутузова и Лизы Кузьменко с сайта [RusVectōrēs.](https://rusvectores.org/ru/models/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве моделей давайте возьмем \n",
    "\n",
    "1) araneum_none_fasttextcbow_300_5_2018 (fasttext) - модель, обученная на интернет-корпусе русского языка\n",
    "\n",
    "\n",
    "2) ruscorpora_upos_skipgram_300_5_2018 (word2vec) - модель, обученная НКРЯ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec + fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существуют несколько форматов, в которых могут храниться модели - .vec и .model \n",
    "\n",
    "1) Первый формат считается классическим вариантом модели word2vec. Для загрузки таакой модели надо воспользоваться методом *KeyedVectors.load_word2vec_format*. \n",
    "Модель может быть бинарной, для ее загрузки надо передать параметр binary, равный True. \n",
    "\n",
    "2) Формат .model - собственный формат gensim. Такую модель надо загружать с помощью метода *KeyedVectors.load*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **1) если модель без тэгов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка модели\n",
    "\n",
    "model_file = '../../data/araneum_none_fasttextcbow_300_5_2018/araneum_none_fasttextcbow_300_5_2018.model'\n",
    "model = KeyedVectors.load(model_file)\n",
    "\n",
    "\n",
    "#проверка наличия слова в словаре\n",
    "\n",
    "lemma = 'заграница'\n",
    "lemma in model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) если модель с POS-тэггингом**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузка модели\n",
    "\n",
    "# model_file = '../../data/ruscorpora_upos_skipgram_300_5_2018.vec'\n",
    "# model_POS = KeyedVectors.load_word2vec_format(model_file, binary=False)\n",
    "\n",
    "\n",
    "#проверка наличия слова в словаре\n",
    "\n",
    "lemma = 'заграница_NOUN'\n",
    "lemma in model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) получение вектора слова**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.10695013e-02,  2.17701886e-02, -4.17113714e-02,  1.04853347e-01,\n",
       "        2.97251549e-02, -5.05348342e-03,  8.50924775e-02, -1.59783456e-02,\n",
       "        8.17752928e-02,  1.82770882e-02,  4.48142625e-02, -3.99412550e-02,\n",
       "        3.01699173e-02,  8.18651915e-02,  5.21745794e-02, -5.25347143e-02,\n",
       "        1.49415746e-01,  1.54418079e-02,  2.05713809e-02, -2.19671372e-02,\n",
       "       -3.50276679e-02, -4.12449650e-02,  3.14566083e-02, -1.22367439e-03,\n",
       "       -7.46390447e-02,  2.48251371e-02,  1.86437406e-02,  4.26618010e-02,\n",
       "        1.04903504e-02, -3.44574675e-02, -7.02655241e-02,  5.20167649e-02,\n",
       "       -4.19732295e-02, -8.22310895e-02,  7.08133215e-03,  8.99268389e-02,\n",
       "       -8.44774917e-02, -4.10604663e-02, -3.39725427e-02, -4.07647751e-02,\n",
       "       -4.11920361e-02, -5.67547791e-02, -7.38171861e-02,  9.61997062e-02,\n",
       "       -3.19693461e-02, -8.84091035e-02, -1.21405562e-02,  5.35934344e-02,\n",
       "        4.13923934e-02, -1.30730838e-01, -4.67060655e-02, -4.94557396e-02,\n",
       "       -1.40484155e-03,  2.28551459e-02,  7.43654296e-02,  7.79571310e-02,\n",
       "        1.04737148e-01,  8.35899916e-03, -1.51861098e-03,  6.45394921e-02,\n",
       "        1.77292880e-02,  8.34287256e-02,  3.37386355e-02, -1.11070752e-01,\n",
       "       -5.16371466e-02, -5.96649339e-03, -1.28995970e-01, -7.12668970e-02,\n",
       "       -1.02591820e-01, -6.07674085e-02, -1.18066901e-02, -1.47895301e-02,\n",
       "       -3.33781466e-02, -9.71935689e-03,  6.01786152e-02, -3.49978432e-02,\n",
       "       -2.78954990e-02, -9.37670842e-02, -7.73874372e-02,  3.08224633e-02,\n",
       "        2.17683334e-02, -7.25540519e-02,  2.88536903e-02,  8.02168529e-03,\n",
       "       -6.70748204e-02, -3.42364609e-02,  3.06607876e-02,  4.46470045e-02,\n",
       "        3.60073037e-02,  1.94718167e-02, -3.34158242e-02, -6.57092333e-02,\n",
       "        3.81694585e-02,  2.61816103e-02, -2.44370494e-02, -7.10618570e-02,\n",
       "       -1.20343350e-01, -4.00529541e-02, -4.73039299e-02, -8.79516006e-02,\n",
       "        7.66381547e-02,  3.58769931e-02, -1.18495347e-02, -1.86823141e-02,\n",
       "        1.18571473e-02,  6.87735379e-02,  1.03831425e-01, -8.43153149e-02,\n",
       "        5.16409846e-03, -1.10952921e-01, -1.91926137e-02,  9.73478332e-02,\n",
       "       -3.66646908e-02, -1.08453430e-01, -2.65418626e-02,  4.12089899e-02,\n",
       "        5.32390624e-02,  2.39786692e-02, -1.23976851e-02, -5.04820934e-03,\n",
       "       -3.74226607e-02, -6.21884875e-02,  6.05405346e-02,  5.78648299e-02,\n",
       "        4.58306000e-02, -4.87128869e-02,  1.54790413e-02,  1.37203010e-02,\n",
       "        4.38570678e-02,  1.07038785e-02, -3.26014943e-02,  1.49811804e-02,\n",
       "        1.64793921e-03,  1.68747045e-02, -1.43095804e-02, -8.00621659e-02,\n",
       "        3.15661319e-02, -5.36045060e-03, -2.16441490e-02,  7.35270604e-03,\n",
       "        8.57836455e-02,  1.30125624e-03, -4.28924747e-02,  3.61450855e-03,\n",
       "        3.23492922e-02, -9.34870634e-03,  1.15727363e-02, -5.25610372e-02,\n",
       "       -2.99600735e-02, -5.57731055e-02, -7.07119587e-04,  1.17514012e-02,\n",
       "       -1.60883471e-01, -2.38974784e-02,  2.94979773e-02,  8.65761470e-03,\n",
       "       -8.23463053e-02,  7.62082189e-02,  5.01060262e-02, -4.00353372e-02,\n",
       "       -4.11777683e-02,  1.11622483e-01,  6.78179190e-02, -4.31496976e-03,\n",
       "       -6.36957586e-02,  1.24151357e-01, -7.57061271e-03,  9.41420719e-02,\n",
       "       -1.87227651e-02, -2.95837000e-02,  8.34589750e-02,  4.09465991e-02,\n",
       "       -3.72978598e-02, -6.72939699e-03, -1.36746421e-01, -4.35629115e-02,\n",
       "       -7.86786973e-02, -6.24808520e-02,  3.52385119e-02,  9.09747705e-02,\n",
       "        8.93134102e-02,  5.93883507e-02, -1.02131451e-02, -1.02355242e-01,\n",
       "        2.07102112e-02, -8.33953246e-02,  6.78783581e-02,  9.37915146e-02,\n",
       "        8.87885168e-02, -6.57795891e-02, -2.39330810e-03, -1.35616912e-02,\n",
       "        5.89502938e-02,  4.07332629e-02, -7.21566156e-02, -4.98559698e-03,\n",
       "        6.90124258e-02, -7.81867430e-02,  2.53684837e-02,  1.20458696e-02,\n",
       "        1.86482584e-03, -4.90406863e-02,  8.40877667e-02,  5.12612946e-02,\n",
       "       -6.11796640e-02, -7.62335360e-02,  1.90574955e-02, -1.72950514e-02,\n",
       "        2.09632181e-02, -3.43655497e-02, -7.24052684e-03, -2.80500129e-02,\n",
       "        1.19609507e-02,  7.00369403e-02, -2.11798437e-02, -2.97471844e-02,\n",
       "       -1.26382455e-01,  4.80246134e-02, -7.87229612e-02,  1.40422434e-01,\n",
       "        4.05784743e-03,  2.08539460e-02, -7.35003203e-02,  1.94781069e-02,\n",
       "       -8.28091875e-02,  8.07852447e-02,  1.07315674e-01,  3.93275805e-02,\n",
       "        4.03772928e-02, -3.44799198e-02, -2.34251693e-02,  3.74870673e-02,\n",
       "       -1.47949709e-02, -1.07578531e-01, -9.06381384e-03,  6.97844923e-02,\n",
       "       -1.00389957e-01, -9.22753811e-02, -9.58153754e-02, -4.97536287e-02,\n",
       "       -5.15872985e-02,  1.04151577e-01,  2.66324263e-02, -3.00854798e-02,\n",
       "        3.68407629e-02, -5.82886748e-02,  1.17953174e-01,  2.88959849e-03,\n",
       "       -2.05231607e-02, -1.64679699e-02, -4.22485493e-04,  3.87210287e-02,\n",
       "       -5.68435974e-02,  1.40736680e-02,  5.95055483e-02,  4.64485846e-02,\n",
       "        1.90412067e-02, -4.81550880e-02,  6.52404055e-02,  2.64489148e-02,\n",
       "        4.26945984e-02, -1.17193991e-02,  6.01800348e-05,  1.96615588e-02,\n",
       "       -4.56573293e-02, -4.38016504e-02, -1.05960080e-02,  8.97553656e-03,\n",
       "        6.26981705e-02, -9.95883159e-03, -7.37756267e-02,  1.90018304e-02,\n",
       "        1.77061018e-02,  8.58223811e-02,  4.96836454e-02, -2.86152828e-02,\n",
       "        6.91956002e-03,  2.12945007e-02, -1.45823201e-02, -9.73290130e-02,\n",
       "       -8.63924548e-02,  5.42813800e-02,  5.04254028e-02, -2.65027974e-02,\n",
       "        3.02954260e-02,  3.61933187e-02, -4.65525910e-02,  1.31475069e-02,\n",
       "       -5.50928265e-02, -6.45257160e-02, -4.48262552e-03,  9.17766988e-02,\n",
       "        6.01465367e-02,  1.31947190e-01,  3.04025188e-02, -1.72889009e-02,\n",
       "       -8.61360356e-02,  5.31748123e-02, -3.24455649e-02,  1.56977531e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['заграница']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.39500e-02,  2.60550e-02,  7.36340e-02,  1.23700e-02,\n",
       "       -3.50900e-02, -1.53790e-02, -1.53120e-02, -4.46420e-02,\n",
       "        2.70790e-02, -1.49646e-01, -2.11150e-02, -9.54970e-02,\n",
       "       -4.53150e-02, -2.29060e-02,  1.88060e-02, -3.26540e-02,\n",
       "        4.14600e-03, -3.33050e-02, -1.11295e-01, -1.99680e-02,\n",
       "        8.52420e-02, -5.65020e-02,  6.37940e-02,  7.47780e-02,\n",
       "        6.07320e-02, -3.06220e-02,  1.18300e-03,  6.26690e-02,\n",
       "       -7.80680e-02,  7.22600e-03,  3.91800e-03,  7.85500e-03,\n",
       "       -2.04750e-02,  1.03410e-02, -2.73720e-02,  1.06103e-01,\n",
       "        1.19590e-02, -6.46130e-02, -9.41660e-02, -1.36470e-02,\n",
       "       -6.39500e-03,  7.87260e-02,  5.41090e-02, -6.22660e-02,\n",
       "        1.17398e-01, -4.33120e-02,  5.32870e-02, -6.18680e-02,\n",
       "        7.07800e-03, -8.10900e-03,  5.02570e-02,  7.70690e-02,\n",
       "        1.63000e-03,  8.76180e-02, -5.56250e-02, -4.33640e-02,\n",
       "       -5.08830e-02,  1.22940e-02,  7.87930e-02, -2.30660e-02,\n",
       "       -1.71630e-02, -3.82160e-02, -3.30880e-02, -6.89400e-03,\n",
       "       -1.27110e-02, -6.76010e-02,  5.86060e-02, -2.27660e-02,\n",
       "        7.24460e-02, -7.19270e-02,  1.52730e-02, -5.30190e-02,\n",
       "        1.51000e-04, -6.21550e-02, -6.54940e-02,  8.03290e-02,\n",
       "       -1.11380e-02,  7.71570e-02,  6.07000e-04, -6.45850e-02,\n",
       "        5.94000e-02,  2.75570e-02,  5.55170e-02, -2.38800e-02,\n",
       "        1.85960e-02, -3.09490e-02,  3.10850e-02,  3.07100e-02,\n",
       "        9.59700e-03,  1.41260e-02, -2.61000e-04,  2.12820e-02,\n",
       "       -3.44150e-02,  2.98390e-02, -3.05000e-03, -2.33320e-02,\n",
       "       -5.03460e-02,  6.74710e-02,  4.55500e-02,  1.04200e-02,\n",
       "        4.58570e-02, -7.28190e-02, -1.47125e-01,  1.94200e-02,\n",
       "       -3.68680e-02, -8.66390e-02,  1.06004e-01,  1.01934e-01,\n",
       "       -5.73390e-02,  1.88120e-02, -4.82180e-02,  6.90860e-02,\n",
       "        3.06250e-02,  1.41770e-02, -3.56990e-02,  3.87800e-02,\n",
       "        6.23680e-02, -5.70100e-03,  2.08230e-02, -6.37890e-02,\n",
       "        7.82900e-02, -1.11912e-01, -3.20180e-02,  2.05700e-02,\n",
       "       -3.68230e-02, -1.82730e-02, -1.23040e-02,  6.33780e-02,\n",
       "       -3.31590e-02, -1.00678e-01, -1.15065e-01,  4.14690e-02,\n",
       "        2.58660e-02, -1.91000e-03,  4.02080e-02,  8.17740e-02,\n",
       "        2.00170e-02, -1.28090e-01, -6.34720e-02, -5.15850e-02,\n",
       "        2.19490e-02,  1.22040e-02,  1.68840e-02, -8.84390e-02,\n",
       "       -2.62070e-02, -8.60750e-02,  5.90200e-03, -3.64940e-02,\n",
       "       -8.40110e-02,  1.29510e-02, -2.51370e-02, -8.03920e-02,\n",
       "        1.56054e-01, -4.34080e-02,  3.28400e-02, -4.29730e-02,\n",
       "        4.40700e-02,  2.73540e-02,  2.04480e-02, -7.69550e-02,\n",
       "       -8.47320e-02, -1.04938e-01, -1.44790e-02,  7.98000e-03,\n",
       "       -6.72020e-02, -6.07000e-04,  1.08704e-01, -1.90600e-02,\n",
       "        8.05800e-02, -2.80880e-02, -2.50020e-02,  1.26534e-01,\n",
       "       -2.95100e-03, -4.92900e-03, -2.59820e-02,  3.12820e-02,\n",
       "        2.83300e-03, -2.89470e-02,  3.50560e-02, -5.30280e-02,\n",
       "        7.68380e-02, -7.75690e-02,  3.25900e-02,  1.63600e-02,\n",
       "       -4.46880e-02,  1.91580e-02,  5.06480e-02, -4.74150e-02,\n",
       "        6.22660e-02,  5.25900e-03,  2.68010e-02, -4.14900e-02,\n",
       "       -5.42800e-02, -2.11200e-02,  1.10360e-02,  9.72700e-02,\n",
       "       -5.33950e-02, -1.23280e-02, -8.61500e-03, -1.58740e-02,\n",
       "       -1.23830e-02, -1.76210e-02,  1.06936e-01,  1.01532e-01,\n",
       "        1.45600e-02,  6.88280e-02, -6.26630e-02,  1.56720e-02,\n",
       "       -7.69410e-02,  3.31260e-02,  1.68580e-02, -1.43103e-01,\n",
       "        1.24340e-02,  2.08120e-02, -4.24350e-02, -9.56670e-02,\n",
       "       -4.32280e-02, -2.94360e-02,  7.50330e-02, -2.83170e-02,\n",
       "        6.65080e-02, -4.91900e-02,  4.51830e-02,  3.71080e-02,\n",
       "       -8.65800e-03,  2.67800e-03, -2.87090e-02,  2.11900e-02,\n",
       "       -7.55590e-02,  4.66600e-02, -1.51930e-02,  6.58290e-02,\n",
       "        3.03280e-02, -1.54670e-01,  2.87550e-02,  8.91950e-02,\n",
       "        5.02350e-02, -1.23420e-02, -2.38920e-02,  7.63000e-04,\n",
       "        8.65400e-03,  1.11940e-02,  7.63580e-02, -1.36000e-04,\n",
       "       -1.38620e-02, -3.66780e-02,  1.16660e-01, -1.23679e-01,\n",
       "       -3.98700e-03, -1.01800e-02, -1.40933e-01,  1.22524e-01,\n",
       "        7.13350e-02,  6.74550e-02, -5.23990e-02, -3.99990e-02,\n",
       "        1.86510e-02,  3.59570e-02,  1.27456e-01,  2.69240e-02,\n",
       "       -2.32990e-02, -3.94000e-04, -1.23391e-01,  6.20690e-02,\n",
       "        2.37460e-02, -3.49010e-02,  4.22650e-02,  1.32905e-01,\n",
       "       -9.43100e-03, -9.40570e-02,  1.32670e-02, -7.45910e-02,\n",
       "       -2.84700e-02, -1.21462e-01, -2.50200e-03, -8.69040e-02,\n",
       "       -2.38540e-02, -2.46450e-02,  5.59400e-03,  3.52670e-02,\n",
       "        1.79120e-02,  1.27630e-02,  3.07250e-02, -1.37065e-01,\n",
       "       -1.53850e-02,  7.01500e-03, -4.02350e-02,  6.83980e-02,\n",
       "       -1.12843e-01, -1.24030e-02, -2.25330e-02,  1.08920e-02,\n",
       "        1.65110e-02, -6.25570e-02,  4.32300e-02, -1.54170e-02,\n",
       "        8.03420e-02,  8.18490e-02,  3.99830e-02, -2.04260e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_POS['заграница_NOUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma = 'заграница'\n",
    "lemma in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = model['заграница']\n",
    "v2 = model_POS.wv['заграница_NOUN']\n",
    "\n",
    "(v1 == v2).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Получение вектора документа\n",
    "\n",
    "Отлично, вектора для слов получены. Что с ними делать дальше? \n",
    "\n",
    "Есть два подхода (а точнее есть один, а второй мы придумали, потому что с одним жить нельзя).\n",
    "> Классика - для получения вектора документа нужно взять и усреднить все вектора его слов\n",
    " \n",
    "$$ vec_{doc} = \\frac {\\sum_{i=0}^{n} vec_i}{len(d)} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# сделали препроцессинг, получили леммы \n",
    "lemmas = ['старинный', 'замок']\n",
    "\n",
    "# создаем вектор-маску\n",
    "lemmas_vectors = np.zeros((len(lemmas), model.vector_size))\n",
    "vec = np.zeros((model.vector_size,))\n",
    "\n",
    "# если слово есть в модели, берем его вектор\n",
    "for idx, lemma in enumerate(lemmas):\n",
    "    if lemma in model:\n",
    "        lemmas_vectors[idx] = model[lemma]\n",
    "        \n",
    "# проверка на случай, если на вход пришел пустой массив\n",
    "if lemmas_vectors.shape[0] is not 0:\n",
    "    vec = np.mean(lemmas_vectors, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Эксперимент - представим документ не в виде одного уредненного вектора, а как матрицу векторов входящих в него слов\n",
    "\n",
    "```\n",
    " слово1 |  v1_300\n",
    " слово2 |  v2_300\n",
    " слово3 |  v3_300\n",
    " слово4 |  v4_300\n",
    "```\n",
    "\n",
    "> Отлично, теперь каждый документ представлен в виде матрицы векторов своих слов. Но нам надо получить близость матрицы документа в коллекции и матрицы входящего запроса. Как? Умножим две матрицы друг на друга - одна матрица размером d x 300, другая q x 300 - получим попарную близость слов из каждого документа - матрицу размером d x q.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возьмем игрушечный пример кейса\n",
    "\n",
    "text1 = 'турция' \n",
    "text2 = 'нужна справка срочно'\n",
    "query = 'быстрая справка'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vec(vec):\n",
    "    return vec / np.linalg.norm(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if __name__ == '__main__':\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# построим матрицы всех документов\n",
    "\n",
    "def create_doc_matrix(text):\n",
    "    lemmas = text.split()\n",
    "    lemmas_vectors = np.zeros((len(lemmas), model.vector_size))\n",
    "    vec = np.zeros((model.vector_size,))\n",
    "\n",
    "    for idx, lemma in enumerate(lemmas):\n",
    "        if lemma in model.wv:\n",
    "            lemmas_vectors[idx] = normalize_vec(model.wv[lemma])\n",
    "            \n",
    "    return lemmas_vectors    \n",
    "\n",
    "\n",
    "text1_m = create_doc_matrix(text1)\n",
    "text2_m = create_doc_matrix(text2)\n",
    "query_m = create_doc_matrix(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 300)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# размер матрицы как и ожидали\n",
    "query_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09587915, 0.01183069]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим на близость слов первого текста и слов запроса\n",
    "text1_m.dot(query_m.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0260624 ,  0.11607588],\n",
       "       [ 0.01341236,  1.00000011],\n",
       "       [ 0.22505549,  0.33582122]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим на близость слов второго текста и слов запроса\n",
    "text2_m.dot(query_m.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10770983955697251, 1.225055597288777]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_m = [text1_m, text2_m]\n",
    "\n",
    "    \n",
    "def search(docs, query, reduce_func=np.max, axis=0):\n",
    "    sims = []\n",
    "    for doc in docs:\n",
    "        sim = doc.dot(query.T)\n",
    "        sim = reduce_func(sim, axis=axis)\n",
    "        sims.append(sim.sum())\n",
    "    print(sims)\n",
    "    return np.argmax(sims)\n",
    "\n",
    "\n",
    "search(docs_m, query_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте поиск по нашему стандартному Covid корпусу с помощью модели на Araneum двумя способами:\n",
    "\n",
    "    1. преобразуйте каждый документ в вектор через усреднение векторов его слов и реализуйте поисковик как \n",
    "    обычно через умножение матрицы документов коллекции на вектор запроса \n",
    "    2. экспериментальный способ - реализуйте поиск ближайшего документа в коллекции к запросу, преобразовав \n",
    "    каждый документ в матрицу (количество слов x размер модели)\n",
    "    \n",
    "Посчитайте качество поиска для каждой модели на тех же данных, что и в предыдущем задании. В качестве препроцессинга используйте две версии - с удалением NER и без удаления.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'araneum_none_fasttextcbow_300_5_2018.model'\n",
    "model = KeyedVectors.load(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### План разработки\n",
    "1. Скопировать препроцессинги из второй домашки\n",
    "2. Сделать функцию для векторного представления документа\n",
    "3. Сделать функцию для матричного представления документа\n",
    "4. Обработать данные без удаления NER\n",
    "    - посмотреть на векторном представлении\n",
    "    - посмотреть на матричном представлении\n",
    "5. Обработать данные с удалением NER. - к сожалению, не успею реализовать. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Препроцессинги и импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string # для .punctuatuion \n",
    "import math # bm25\n",
    "from collections import OrderedDict # для сортировки\n",
    "from collections import Counter # для матрицы бм25\n",
    "\n",
    "from razdel import tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from natasha import (\n",
    "    Segmenter,\n",
    "    NewsNERTagger,\n",
    "    NewsEmbedding,\n",
    "    Doc\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "segmenter = Segmenter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# мой препроцессинг\n",
    "morph = MorphAnalyzer()\n",
    "stop = set(stopwords.words('russian'))\n",
    "\n",
    "def prep(unprep):\n",
    "    unprep = str(unprep)\n",
    "    unprep = unprep.lower()\n",
    "    unprep = unprep.replace('\\n', ' ') #.punctuation не прочтет\n",
    "    unprep = unprep.translate(str.maketrans('', '', string.punctuation))# https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string\n",
    "    unprep_tokenized = list(tokenize(unprep))\n",
    "    lemmas = [morph.parse(i.text)[0].normal_form for i in unprep_tokenized]\n",
    "    words = [i for i in lemmas if i not in stop]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# наташа препроцессинг\n",
    "def preprocess_with_natasha(text: str) -> str:\n",
    "    text = str(text)\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_ner(ner_tagger)\n",
    "    positions = []\n",
    "    for element in doc.spans:\n",
    "        positions.append([element.start, element.stop])\n",
    "    lst = list(text)\n",
    "    for i in positions[::-1]: # iterate from behind so index does not shrink inwards\n",
    "        del lst[slice(*i)]\n",
    "    text = ''.join(lst)\n",
    "    text = text.replace('  ', ' ')\n",
    "    text = text.replace('  ', ' ')\n",
    "    text = text.replace(' .', '.')\n",
    "    print(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция для векторного представления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# строю по примеру выше с нормализацией\n",
    "def mean_vec(text):\n",
    "    # пока что пустой вектор требуемого размера\n",
    "    all_words_vec = np.zeros((len(text), model.vector_size))\n",
    "    # добавляю слово в вектор, если оно встречается и в тексте, и в модели \n",
    "    for word_index, word in enumerate(text):\n",
    "        if word in model:\n",
    "            # нормализация\n",
    "            all_words_vec[word_index] = normalize_vec(model[word])\n",
    "    return normalize_vec(np.mean(all_words_vec, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция для матричного представления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# почти то же самое, что векторная функция\n",
    "def create_doc_matrix(text):\n",
    "    all_words_vec = np.zeros((len(text), model.vector_size))\n",
    "    for word_index, word in enumerate(text):\n",
    "        if word in model.wv:\n",
    "            all_words_vec[word_index] = normalize_vec(model[word])\n",
    "    return all_words_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка данных без удаления ИмСущ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_df = pd.read_excel(\"answers_base.xlsx\")\n",
    "questions_df = pd.read_excel(\"queries_base.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_df.rename(columns={'Номер связки': 'connection', 'Текст вопросов': 'text'}, inplace=True)\n",
    "questions_df.rename(columns={'Номер связки\\n': 'connection', 'Текст вопроса': 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egor/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(questions_df, test_size=0.3)\n",
    "qa_df = pd.concat([answers_df, train_df])\n",
    "qa_df = qa_df.drop(columns = ['Unnamed: 3','Unnamed: 4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 690/690 [00:09<00:00, 73.30it/s]\n",
      "100%|██████████| 1652/1652 [00:23<00:00, 71.80it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df_done = []\n",
    "qa_df_done = []\n",
    "\n",
    "for entry in tqdm(test_df['text']):\n",
    "    test_df_done.append(prep(entry))\n",
    "for entry in tqdm(qa_df['text']):\n",
    "    qa_df_done.append(prep(entry))\n",
    "\n",
    "both_done = qa_df_done + test_df_done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим с векторами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1652, 300)\n",
      "(690, 300)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([mean_vec(text) for text in qa_df_done])\n",
    "X_test = np.array([mean_vec(text) for text in test_df_done])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на точность\n",
    "rating = X_train.dot(X_test.T).argmax(axis=0)\n",
    "rating = np.array(rating)\n",
    "rating_en = enumerate(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 0\n",
    "# сравним связки\n",
    "for test_index, prediction in rating_en:\n",
    "    # проверка на NaN\n",
    "    if math.isnan(test_df.iloc[test_index].connection) or math.isnan(qa_df.iloc[prediction].connection):\n",
    "        continue\n",
    "\n",
    "    # если в тесте и трейне совпала связка по посчитанным индексам из рейтинга, модели плюс очко\n",
    "    if int(test_df.iloc[test_index].connection) == int(qa_df.iloc[prediction].connection):\n",
    "        score += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3521739130434783\n"
     ]
    }
   ],
   "source": [
    "print(score / len(rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "почему-то сильно упало качество"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим то же самое с матрицами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egor/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1652,)\n",
      "(690,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([create_doc_matrix(text) for text in qa_df_done])\n",
    "X_test = np.array([create_doc_matrix(text) for text in test_df_done])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(docs, query, reduce_func=np.max, axis=0):\n",
    "    sims = []\n",
    "    for doc in docs:\n",
    "        sim = doc.dot(query.T)\n",
    "        sim = reduce_func(sim, axis=axis)\n",
    "        sims.append(sim.sum())\n",
    "    return np.argmax(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "690it [35:27,  3.08s/it]\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "# сравним связки\n",
    "for test_index, query in tqdm(enumerate(X_test)):\n",
    "    best_index = search(X_train, query)\n",
    "    # проверка на NaN\n",
    "    if math.isnan(test_df.iloc[test_index].connection) or math.isnan(qa_df.iloc[best_index].connection):\n",
    "        continue\n",
    "\n",
    "    # если в тесте и трейне совпала связка по посчитанным индексам из рейтинга, модели плюс очко\n",
    "    if int(test_df.iloc[test_index].connection) == int(qa_df.iloc[best_index].connection):\n",
    "        score += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17101449275362318\n"
     ]
    }
   ],
   "source": [
    "print(score / len(rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "очевидно, что-то где-то пошло не так"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
